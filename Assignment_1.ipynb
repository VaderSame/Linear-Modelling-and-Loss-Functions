{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade: /100 points\n",
    "\n",
    "# Assignment 01: Supervised learning, Linear models, and Loss functions\n",
    "\n",
    "In this assignment, you're going to write your own methods to fit a linear model using either an OLS or LAD cost function.  \n",
    "\n",
    "## Data set \n",
    "\n",
    "For this assignment, we will examine some data representing possums in Australia and New Guinea. The data frame contains 46 observations on the following 6 variables:\n",
    "\n",
    "* sex: Sex, either m (male) or f (female).\n",
    "* age: Age in years.\n",
    "* headL: Head length, in mm.\n",
    "* skullW: Skull width, in mm.\n",
    "* totalL: Total length, in cm.\n",
    "* tailL: Tail length, in cm.\n",
    "\n",
    "## Follow These Steps Before Submitting\n",
    "\n",
    "You may need to install packages as follows:\n",
    "\n",
    "`python -m pip install matplotlib numpy scipy pandas scikit-learn`\n",
    "\n",
    "Once you are finished, ensure to complete the following steps.\n",
    "\n",
    "1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "\n",
    "2.  Fix any errors which result from this.\n",
    "\n",
    "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
    "\n",
    "4.  Submit your completed notebook to OWL by the deadline.\n",
    "\n",
    "\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary packages: \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as so\n",
    "from scipy.optimize import minimize \n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1\n",
    "### Question 1.1:  /10 points\n",
    "\n",
    "\n",
    "Read in the `possum.csv` file as a `pandas.DataFrame`.  Investigate the relationship between the possum's age and its tail length by plotting a scatter plot of the `age` and `tailL` columns. Add an `alpha`(transparency of the plotted dots) in case some data are overlapping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possum data is read\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the data with pandas\n",
    "possum_data = pd.read_csv(\"possum.csv\")\n",
    "print(\"possum data is read\")\n",
    "\n",
    "# Make the scatter plot (don't forget the axis labels)\n",
    "plt.scatter(possum_data['age'], possum_data['tailL'], alpha=0.9)\n",
    "plt.title('ScatterPlot of Possum Age vs Tail Length')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Tail Length (mm)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2: /5 point\n",
    "\n",
    "Recall that the linear model, we obtain predictions by computing \n",
    "\n",
    "$$ \\hat{\\mathbf{y}} = \\mathbf{X} \\hat{\\beta} $$\n",
    "\n",
    "Here, $\\mathbf{X}$ is a design matrix which includes a column of ones, $\\hat{\\beta}$ are coefficients, and $\\hat{\\mathbf{y}}$ are outcomes.  Write a function `linearModelPredict` to compute linear model predictions given data and a coefficient vector.  The function should take as it's arguments a 1d-array of coefficients `b` and the design matrix `X` as a 2d-array and return linear model predictions `yp`.\n",
    "\n",
    "Test the function by setting \n",
    "\n",
    "```\n",
    "X = np.array([[1,0],[1,-1],[1,2]])\n",
    "b = np.array([0.1,0.3])\n",
    "```\n",
    "and call your function with these values! \n",
    "\n",
    "Report $\\hat{\\mathbf{y}}$. \n",
    "What is the dimensionality of the numpy-array that you get back? \n",
    "\n",
    "Hint:  Read the documentation for `np.dot` or the `@` operator in `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1, -0.2,  0.7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linearModelPredict(b,X):\n",
    "    yp = np.dot(b,X)\n",
    "    return yp\n",
    "\n",
    "# Always important: Test the new function you have written! \n",
    "X = np.array([[1,0],[1,-1],[1,2]])\n",
    "b = np.array([0.1,0.3])\n",
    "\n",
    "# By the way: What happens when b is a 2d-array? \n",
    "yp = linearModelPredict(X,b)\n",
    "\n",
    "yp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3: /15 points\n",
    "\n",
    "Write a function `linearModelLossRSS` which computes and returns the loss function for an OLS model parameterized by $\\beta$, as well as the gradient of the loss.  The function should take as its first argument a 1d-array `beta` of coefficients for the linear model, as its second argument the design matrix `X` as a 2d-array, and as its third argument a 1d-array `y` of observed outcomes.\n",
    "\n",
    "Test the function with the values \n",
    "\n",
    "```\n",
    "X = np.array([[1,0],[1,-1],[1,2]])\n",
    "b = np.array([0.1,0.3])\n",
    "y = np.array([0,0.4,2]) \n",
    "```\n",
    "\n",
    "Report the loss and the gradient. \n",
    "\n",
    "**Written answer**: To minimize the cost do you need increase or decrease the value of the parameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual Sum of Squares (RSS): 2.06\n",
      "Gradient of the loss: [-3.6 -4. ]\n"
     ]
    }
   ],
   "source": [
    "def linearModelLossRSS(b,X,y):\n",
    "    # Compute the predicted values\n",
    "    y_pred = np.dot(X,b)\n",
    "    \n",
    "    # Compute the residuals \n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    # Compute the Residuals Sum of Squares \n",
    "    residual_sum_of_squares  = np.sum (residuals**2)\n",
    "    \n",
    "    # Compute the gradient of the RSS with respect to the coefficients b\n",
    "    gradient = -2 * np.dot(X.T, residuals)\n",
    "    \n",
    "    return (residual_sum_of_squares, gradient)\n",
    "\n",
    "# Test the function with the given values\n",
    "X = np.array([[1, 0], [1, -1], [1, 2]])\n",
    "b = np.array([0.1, 0.3])\n",
    "y = np.array([0, 0.4, 2])\n",
    "\n",
    "# Call the function to compute the loss and gradient\n",
    "residual_sum_of_squares, gradient = linearModelLossRSS(b, X, y)\n",
    "\n",
    "# Output the RSS and gradient\n",
    "print(\"Residual Sum of Squares (RSS):\", residual_sum_of_squares)\n",
    "print(\"Gradient of the loss:\", gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize the cost , we need to update the parameter values in the opposite direction of the gradient. In this case the gradient values are negetive for both the parameters , we should increase the values of parameters to move towards the minimum. \n",
    "\n",
    "The gradient suggests how to adjust the co-effiecnts beta to reducs the loss. If the gradient is negative for a parameter , increasing the parameter will reduce the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.4:  /15 points. \n",
    "\n",
    "Now that you've implemented a loss function in question 1.3, it is now time to minimize it!\n",
    "\n",
    "Write a function `linearModelFit` to fit a linear model.  The function should take as its first argument the design matrix `X` as a 2d-array, as its second argument a 1d-array `y` of outcomes, and as its third argument a function  `lossfcn` which returns as a tuple the value of the loss, as well as the gradient of the loss. As a result, it should return the estimated betas and the R2. \n",
    "\n",
    "Test the function with the values: \n",
    "```\n",
    "X = np.array([[1,0],[1,-1],[1,2]])\n",
    "y = np.array([0,0.4,2]) \n",
    "```\n",
    "\n",
    "Report best parameters and the fitted R2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Betas: [0.6 0.6]\n",
      "Fitted R²: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Function to fit the model using gradient descent\n",
    "def linearModelFit(X, y, lossfcn=linearModelLossRSS):\n",
    "    \n",
    "    # Initial guess for the coefficients (betas)\n",
    "    bstart = [0, 0]\n",
    "    \n",
    "    # Use scipy's minimize function to optimize the loss function\n",
    "    RESULT = minimize(lossfcn, bstart, args=(X, y), jac=True)\n",
    "    estimated_betas = RESULT.x  # Extract the optimized betas\n",
    "    \n",
    "    # Compute the predicted values using the final betas\n",
    "    y_pred = np.dot(X, estimated_betas)\n",
    "    \n",
    "    # Calculate R² score\n",
    "    ss_res = np.sum((y - y_pred) ** 2)  # Residual sum of squares\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)  # Total sum of squares\n",
    "    R2 = 1 - (ss_res / ss_tot)  # R² formula\n",
    "    \n",
    "    return estimated_betas, R2\n",
    "\n",
    "# Test the function with the given values\n",
    "X = np.array([[1, 0], [1, -1], [1, 2]])\n",
    "y = np.array([0, 0.4, 2])\n",
    "\n",
    "# Fit the model and get the estimated betas and R² value\n",
    "estimated_betas, R2 = linearModelFit(X, y, linearModelLossRSS)\n",
    "\n",
    "# Output the estimated betas and fitted R²\n",
    "print(\"Estimated Betas:\", estimated_betas)\n",
    "print(\"Fitted R²:\", R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.5: /15 points\n",
    "\n",
    "Use the above functions to fit your model to the possum data. Then use your model and the fitted parameters to make predictions along a grid of equally spaced possum ages.  \n",
    "\n",
    "Plot the data and add a line for the predicted values. You can get these by generating a new X-matrix with equally spaced ages (using for example np.linspace). Also report the R2 value for the fit. You can do this by either printing out the R2 of the fit or putting it on your plot via the `annotate` function in matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns (age and tail length)\n",
    "ages = possum_data['age'].values\n",
    "tail_lengths = possum_data['tailL'].values\n",
    "\n",
    "# Create the design matrix using np.c_ (adding a column of ones for the intercept)\n",
    "X = np.c_[np.ones(ages.shape[0]), ages]\n",
    "y = tail_lengths\n",
    "\n",
    "# Call your fitting function \n",
    "estimated_betas, R2 = linearModelFit(X, y, linearModelLossRSS)\n",
    "\n",
    "# Create the scatter plot (correcting the x-values to use 'ages')\n",
    "plt.scatter(ages, y, color='blue', label='Actual Data')\n",
    "\n",
    "# Create a new X matrix with equally spaced data\n",
    "ages_grid = np.linspace(ages.min(), ages.max(), 100)  # Equally spaced ages\n",
    "X_grid = np.c_[np.ones(ages_grid.shape), ages_grid]  # Design matrix for predictions\n",
    "\n",
    "# Generate predictions using the fitted model (estimated betas)\n",
    "y_pred = np.dot(X_grid, estimated_betas)\n",
    "\n",
    "# Plot the predicted values as a line\n",
    "plt.plot(ages_grid, y_pred, color='red', label=f'Predicted (R² = {R2:.2f})')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Possum Age')\n",
    "plt.ylabel('Tail Length')\n",
    "plt.title('Possum Age vs Tail Length with Fitted Line')\n",
    "plt.legend()\n",
    "\n",
    "# Optionally annotate the R² value on the plot\n",
    "plt.annotate(f'R² = {R2:.2f}', xy=(1.05, 0.6), xycoords='axes fraction', fontsize=12, color='red')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Output the R² value\n",
    "print(f\"R²: {R2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: LAD Regression\n",
    "\n",
    "### Question 2.1:  /15 points\n",
    "\n",
    "In the previous section, we worked with the squared loss.  Now, we'll implement a linear model with least absolute deviation loss.\n",
    "\n",
    "Write a function `linearModelLossLAD` which computes the least absolute deviation loss function for a linear model  parameterized by $\\beta$, as well as the gradient of the loss.  The function should take as its first argument a 1d-array `beta` of coefficients for the linear model, as its second argument the design matrix `X` as a 2d-array, and as its third argument a 1d-array `y` of observed outcomes.\n",
    "\n",
    "Test the function with the values \n",
    "\n",
    "```\n",
    "X = np.array([[1,0],[1,-1],[1,2]])\n",
    "b = np.array([0.1,0.3])\n",
    "y = np.array([0,0.4,2]) \n",
    "```\n",
    "\n",
    "Report the loss and the gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linearModelLossLAD function\n",
    "def linearModelLossLAD(beta, X, y):\n",
    "    # 1. Compute the predicted values (y_pred = X * beta)\n",
    "    y_pred = np.dot(X, beta)\n",
    "    \n",
    "    # 2. Compute the residuals (difference between actual and predicted values)\n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    # 3. Compute the Least Absolute Deviations (LAD) loss\n",
    "    lad_loss = np.sum(np.abs(residuals))\n",
    "    \n",
    "    # 4. Compute the gradient of the LAD loss\n",
    "    gradient = -np.dot(X.T, np.sign(residuals))\n",
    "    \n",
    "    return lad_loss, gradient\n",
    "\n",
    "# Test the function with the given values\n",
    "X = np.array([[1, 0], [1, -1], [1, 2]])\n",
    "b = np.array([0.1, 0.3])\n",
    "y = np.array([0, 0.4, 2])\n",
    "\n",
    "# Call the function to compute the loss and gradient\n",
    "lad_loss, gradient = linearModelLossLAD(b, X, y)\n",
    "\n",
    "# Output the LAD loss and gradient\n",
    "print(\"LAD Loss:\", lad_loss)\n",
    "print(\"Gradient of the LAD Loss:\", gradient)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2: /10 points\n",
    "\n",
    "\n",
    "Use the above functions to fit your LAD model. Use your model to make predictions along a grid of equally spaced possum ages.  Once fit, add the fitted line to the scatter plot as in question 1.5.  Also report the R2-value. \n",
    "\n",
    "**Written answer**: What is the difference in the fit obtained with an L1 as compared to the L2 cost function? Which one has a higher R2 value? Why?  \n",
    "\n",
    "Note: If you recieve an error from the optimizer, it may be because the loss function for the LAD model is not differentiable at its minimum.  This will lead to some gradient based optimizers to fail to converge.  If this happens to you then pass `method=\"Powell\"` to `scipy.optimize.minimize`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns (age and tail length)\n",
    "ages = possum_data['age'].values\n",
    "tail_lengths = possum_data['tailL'].values\n",
    "\n",
    "# Create the design matrix using np.c_ (adding a column of ones for the intercept)\n",
    "X = np.c_[np.ones(ages.shape[0]), ages]\n",
    "y = tail_lengths\n",
    "\n",
    "# Define the LAD model fitting function (using Powell method to avoid non-differentiability issues)\n",
    "def linearModelFitLAD(X, y):\n",
    "    # Initial guess for the coefficients (betas)\n",
    "    bstart = [0, 0]\n",
    "    \n",
    "    # Use scipy's minimize function with the Powell method\n",
    "    RESULT = minimize(linearModelLossLAD, bstart, args=(X, y), jac=True, method='Powell')\n",
    "    estimated_betas = RESULT.x  # Extract the optimized betas\n",
    "    \n",
    "    # Compute the predicted values using the final betas\n",
    "    y_pred = np.dot(X, estimated_betas)\n",
    "    \n",
    "    # Calculate R² score\n",
    "    ss_res = np.sum((y - y_pred) ** 2)  # Residual sum of squares\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)  # Total sum of squares\n",
    "    R2 = 1 - (ss_res / ss_tot)  # R² formula\n",
    "    \n",
    "    return estimated_betas, R2\n",
    "\n",
    "# Fit the LAD model to the possum age and tail length data\n",
    "estimated_betas_lad, R2_lad = linearModelFitLAD(X, y)\n",
    "\n",
    "# Create a scatter plot for the actual data\n",
    "plt.scatter(ages, y, color='blue', label='Actual Data')\n",
    "\n",
    "# Create a new X matrix with equally spaced possum ages for predictions\n",
    "ages_grid = np.linspace(ages.min(), ages.max(), 100)  # Equally spaced ages\n",
    "X_grid = np.c_[np.ones(ages_grid.shape), ages_grid]  # Design matrix for predictions\n",
    "\n",
    "# Generate predictions using the LAD model\n",
    "y_pred_lad = np.dot(X_grid, estimated_betas_lad)\n",
    "\n",
    "# Plot the LAD predicted values as a line\n",
    "plt.plot(ages_grid, y_pred_lad, color='red', label=f'LAD Predicted (R² = {R2_lad:.2f})')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Possum Age')\n",
    "plt.ylabel('Tail Length')\n",
    "plt.title('LAD Model: Possum Age vs Tail Length with Fitted Line')\n",
    "plt.legend()\n",
    "\n",
    "# Optionally annotate the R² value on the plot\n",
    "plt.annotate(f'LAD R² = {R2_lad:.2f}', xy=(1.02, 0.9), xycoords='axes fraction', fontsize=12, color='red')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Output the LAD R² value\n",
    "print(f\"LAD R²: {R2_lad:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written answer: The L1 (LAD) model is more robust to outliers becuase it minimizes the absolute deviations. While the L2(OLS) model minimizes the squared deviations which means it is more susceptible to large errors.\n",
    "\n",
    "R² vlaue for OLS model is typically higher than the LAD model , epspecially in the cases where data has a normal distribution and no major outliers. On the other hand if data does contain outliers , LAD model might give a better fit with a higher R^2 because it is not influenced by extreme values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3: /15 points\n",
    "\n",
    "Fit an OLS model to the possum data with the `linear_model` module from the `sklearn` package by using the `LinearRegression` class.  In no more than two sentences, comment on the rsquared values from `sklearn` and the rsquared values from your models. Are they similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the OLS model using sklearn\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(ages, tail_lengths)\n",
    "\n",
    "# Get the predicted values from the OLS model\n",
    "y_pred_ols = ols_model.predict(ages)\n",
    "\n",
    "# Calculate the R-squared value using sklearn\n",
    "R2_sklearn = r2_score(tail_lengths, y_pred_ols)\n",
    "\n",
    "# Output the R² value from sklearn\n",
    "print(f\"Sklearn OLS R²: {R2_sklearn:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R² values from `skearn` and the custom OLS model should be similar or almost identical because both minimize the same sum of squared residues (L2 normalization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
